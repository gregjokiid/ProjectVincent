{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Constants\nIMG_WIDTH, IMG_HEIGHT = 224, 224\nNUM_CLASSES = 16  \nBATCH_SIZE = 32\nLEARNING_RATE = 0.0001\nNUM_EPOCHS = 10\n\n# pre-trained on ImageNet\nbase_model = ResNet50(\n    weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n)\n\n# Add custom layers\nx = base_model.output\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\npredictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\n# ResNet50 model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze base model layers\nfor layer in base_model.layers:\n    layer.trainable = True\n\n# Compile model\noptimizer = Adam(learning_rate=LEARNING_RATE)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Load and preprocess data\ntrain_datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/flowers/flowers/',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/flowers/flowers/',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    '/kaggle/input/flowers/flowers/',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)\n\n# Train the model\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    epochs=NUM_EPOCHS\n)\n\n# Evaluate the model \ntest_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-07T12:25:06.778257Z","iopub.execute_input":"2023-06-07T12:25:06.778543Z","iopub.status.idle":"2023-06-07T12:44:05.869106Z","shell.execute_reply.started":"2023-06-07T12:25:06.778512Z","shell.execute_reply":"2023-06-07T12:44:05.868018Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 3s 0us/step\nFound 12599 images belonging to 16 classes.\nFound 3141 images belonging to 16 classes.\nFound 15740 images belonging to 16 classes.\nEpoch 1/10\n393/393 [==============================] - 171s 317ms/step - loss: 1.4917 - accuracy: 0.8522 - val_loss: 5.1805 - val_accuracy: 0.1097\nEpoch 2/10\n393/393 [==============================] - 82s 209ms/step - loss: 0.9463 - accuracy: 0.9576 - val_loss: 1.5373 - val_accuracy: 0.7844\nEpoch 3/10\n393/393 [==============================] - 82s 210ms/step - loss: 0.7616 - accuracy: 0.9735 - val_loss: 1.0352 - val_accuracy: 0.8973\nEpoch 4/10\n393/393 [==============================] - 80s 202ms/step - loss: 0.6387 - accuracy: 0.9788 - val_loss: 0.7899 - val_accuracy: 0.9308\nEpoch 5/10\n393/393 [==============================] - 82s 209ms/step - loss: 0.5377 - accuracy: 0.9833 - val_loss: 0.7405 - val_accuracy: 0.9257\nEpoch 6/10\n393/393 [==============================] - 82s 209ms/step - loss: 0.4641 - accuracy: 0.9842 - val_loss: 0.6498 - val_accuracy: 0.9267\nEpoch 7/10\n393/393 [==============================] - 83s 212ms/step - loss: 0.3873 - accuracy: 0.9876 - val_loss: 0.6754 - val_accuracy: 0.9110\nEpoch 8/10\n393/393 [==============================] - 79s 202ms/step - loss: 0.3353 - accuracy: 0.9882 - val_loss: 0.5523 - val_accuracy: 0.9292\nEpoch 9/10\n393/393 [==============================] - 80s 203ms/step - loss: 0.2842 - accuracy: 0.9894 - val_loss: 0.4927 - val_accuracy: 0.9385\nEpoch 10/10\n393/393 [==============================] - 82s 210ms/step - loss: 0.2478 - accuracy: 0.9890 - val_loss: 0.5269 - val_accuracy: 0.9152\n491/491 [==============================] - 41s 83ms/step - loss: 0.2980 - accuracy: 0.9705\nTest Loss: 0.29798170924186707\nTest Accuracy: 0.9704684615135193\n","output_type":"stream"}]}]}